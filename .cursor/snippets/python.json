{
  "FastAPI Route": {
    "prefix": "faroute",
    "body": [
      "from fastapi import APIRouter, Depends, HTTPException, status",
      "from typing import List, Optional",
      "from app.models.${1:model} import ${2:Model}, ${2:Model}Create, ${2:Model}Response",
      "from app.services.${3:service} import ${4:Service}",
      "",
      "router = APIRouter(prefix=\"/${5:prefix}\", tags=[\"${6:tag}\"])",
      "",
      "",
      "@router.post(\"/\", response_model=${2:Model}Response, status_code=status.HTTP_201_CREATED)",
      "async def create_${7:item}(${8:item}: ${2:Model}Create, service: ${4:Service} = Depends()):",
      "    \"\"\"",
      "    Create a new ${7:item}.",
      "    \"\"\"",
      "    return await service.create(${8:item})",
      "",
      "",
      "@router.get(\"/{${9:id}}\", response_model=${2:Model}Response)",
      "async def get_${7:item}(${9:id}: int, service: ${4:Service} = Depends()):",
      "    \"\"\"",
      "    Get a ${7:item} by ID.",
      "    \"\"\"",
      "    ${7:item} = await service.get(${9:id})",
      "    if not ${7:item}:",
      "        raise HTTPException(",
      "            status_code=status.HTTP_404_NOT_FOUND,",
      "            detail=f\"${2:Model} with ID {${9:id}} not found\"",
      "        )",
      "    return ${7:item}",
      ""
    ],
    "description": "Create a FastAPI route with CRUD operations"
  },
  "Pydantic Model": {
    "prefix": "pymodel",
    "body": [
      "from pydantic import BaseModel, Field",
      "from typing import List, Optional",
      "from datetime import datetime",
      "",
      "",
      "class ${1:Model}Base(BaseModel):",
      "    \"\"\"Base ${1:Model} model with common attributes.\"\"\"",
      "    ${2:name}: str = Field(..., description=\"The name of the ${1:Model}\")",
      "    ${3:description}: Optional[str] = Field(None, description=\"Description of the ${1:Model}\")",
      "",
      "",
      "class ${1:Model}Create(${1:Model}Base):",
      "    \"\"\"${1:Model} creation model.\"\"\"",
      "    pass",
      "",
      "",
      "class ${1:Model}(${1:Model}Base):",
      "    \"\"\"${1:Model} model with all attributes.\"\"\"",
      "    id: int = Field(..., description=\"The unique identifier\")",
      "    created_at: datetime = Field(..., description=\"Creation timestamp\")",
      "    updated_at: datetime = Field(..., description=\"Last update timestamp\")",
      "",
      "    class Config:",
      "        orm_mode = True",
      "",
      "",
      "class ${1:Model}Response(${1:Model}):",
      "    \"\"\"${1:Model} response model.\"\"\"",
      "    pass",
      ""
    ],
    "description": "Create a Pydantic model with base, create, and response classes"
  },
  "LangChain Chain": {
    "prefix": "lcchain",
    "body": [
      "from langchain.prompts import PromptTemplate",
      "from langchain.chains import LLMChain",
      "from langchain.chat_models import ChatOpenAI",
      "from langchain.output_parsers import PydanticOutputParser",
      "from pydantic import BaseModel, Field",
      "from typing import List, Optional",
      "",
      "",
      "class ${1:Output}(BaseModel):",
      "    \"\"\"Output schema for the ${2:chain} chain.\"\"\"",
      "    ${3:field1}: str = Field(..., description=\"${4:Description of field1}\")",
      "    ${5:field2}: List[str] = Field(..., description=\"${6:Description of field2}\")",
      "",
      "",
      "class ${7:Chain}:",
      "    \"\"\"${8:Description of the chain}.\"\"\"",
      "",
      "    def __init__(self, model_name: str = \"gpt-4\", temperature: float = 0.0):",
      "        \"\"\"Initialize the chain with the specified model and temperature.\"\"\"",
      "        self.llm = ChatOpenAI(model_name=model_name, temperature=temperature)",
      "        self.output_parser = PydanticOutputParser(pydantic_object=${1:Output})",
      "        self.prompt = PromptTemplate(",
      "            template=\"\"\"${9:Prompt template with {input_variable} placeholders.}",
      "",
      "            {format_instructions}",
      "            \"\"\",",
      "            input_variables=[\"${10:input_variable}\"],",
      "            partial_variables={",
      "                \"format_instructions\": self.output_parser.get_format_instructions()",
      "            },",
      "        )",
      "        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)",
      "",
      "    async def generate(self, ${10:input_variable}: str) -> ${1:Output}:",
      "        \"\"\"Generate output based on the input.\"\"\"",
      "        result = await self.chain.arun(${10:input_variable}=${10:input_variable})",
      "        return self.output_parser.parse(result)",
      ""
    ],
    "description": "Create a LangChain chain with Pydantic output parser"
  },
  "FastAPI Main": {
    "prefix": "famain",
    "body": [
      "from fastapi import FastAPI, HTTPException",
      "from fastapi.middleware.cors import CORSMiddleware",
      "from app.api.routes import ${1:route1}, ${2:route2}",
      "from app.core.config import settings",
      "import logging",
      "",
      "# Configure logging",
      "logging.basicConfig(",
      "    level=settings.LOG_LEVEL,",
      "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",",
      ")",
      "logger = logging.getLogger(__name__)",
      "",
      "app = FastAPI(",
      "    title=settings.PROJECT_NAME,",
      "    description=settings.PROJECT_DESCRIPTION,",
      "    version=settings.VERSION,",
      "    docs_url=\"/docs\",",
      "    redoc_url=\"/redoc\",",
      ")",
      "",
      "# Configure CORS",
      "app.add_middleware(",
      "    CORSMiddleware,",
      "    allow_origins=settings.ALLOWED_ORIGINS,",
      "    allow_credentials=True,",
      "    allow_methods=[\"*\"],",
      "    allow_headers=[\"*\"],",
      ")",
      "",
      "# Include routers",
      "app.include_router(${1:route1}.router)",
      "app.include_router(${2:route2}.router)",
      "",
      "",
      "@app.get(\"/health\")",
      "async def health_check():",
      "    \"\"\"Health check endpoint.\"\"\"",
      "    return {\"status\": \"ok\"}",
      "",
      "",
      "@app.exception_handler(Exception)",
      "async def global_exception_handler(request, exc):",
      "    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)",
      "    return HTTPException(",
      "        status_code=500,",
      "        detail=\"An unexpected error occurred. Please try again later.\",",
      "    )",
      ""
    ],
    "description": "Create a FastAPI main application file"
  },
  "Config Settings": {
    "prefix": "faconfig",
    "body": [
      "from pydantic import BaseSettings, Field",
      "from typing import List",
      "import os",
      "from dotenv import load_dotenv",
      "",
      "# Load environment variables from .env file",
      "load_dotenv()",
      "",
      "",
      "class Settings(BaseSettings):",
      "    \"\"\"Application settings.\"\"\"",
      "",
      "    # Project info",
      "    PROJECT_NAME: str = \"${1:EMA-AI}\"",
      "    PROJECT_DESCRIPTION: str = \"${2:AI service for generating adventure recommendations}\"",
      "    VERSION: str = \"0.1.0\"",
      "",
      "    # API settings",
      "    HOST: str = Field(default=\"0.0.0.0\", env=\"HOST\")",
      "    PORT: int = Field(default=8000, env=\"PORT\")",
      "    LOG_LEVEL: str = Field(default=\"info\", env=\"LOG_LEVEL\")",
      "    ALLOWED_ORIGINS: List[str] = Field(",
      "        default=[\"http://localhost:3000\", \"http://localhost:8000\"],",
      "        env=\"ALLOWED_ORIGINS\",",
      "    )",
      "",
      "    # OpenAI settings",
      "    OPENAI_API_KEY: str = Field(..., env=\"OPENAI_API_KEY\")",
      "    OPENAI_MODEL: str = Field(default=\"gpt-4\", env=\"OPENAI_MODEL\")",
      "",
      "    class Config:",
      "        env_file = \".env\"",
      "        case_sensitive = True",
      "",
      "",
      "# Create settings instance",
      "settings = Settings()",
      ""
    ],
    "description": "Create a configuration settings file for FastAPI"
  }
}
